{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Linear Regression\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Causation versus Correlation\n\n"]},{"cell_type":"markdown","metadata":{},"source":[" Back in my home country, and before the hippy movement changed our culture, kids, who were curious about where the babies come from, were told that they are brought by the stork (a large bird, see Fig.[fig:storksa](fig:storksa)). Storks were indeed a common sight in rural areas, and large enough to sell this story to a 3-year-old.\n\n![img](Ringedwhitestork.jpg \"The Stork. Image by Soloneying, Wikimedia Downloaded Nov 22, 2019.\")\n\nSadly, as grown-up scientists with a penchant for critical thinking, we want to know if there is data to support this idea. Specifically, we should see a good correlation between the number of storks and the number of babies. Low and behold, these two variables actually correlate in a statistically significant way. Countries with larger stork populations have higher birthrates.  Since both variables increase together, this is called a positive correlation. See Fig. [4](#org152a049)\n\n![img](./stork_new.png \"The birthrate and the number of stork pairs correlate in a statistically significant way. This analysis suggests that each stork pair delivers about 29 human babies, and that about 225 thousand babies were born otherwise. Data after Matthews 2000.\")\n\nNow, does this prove that the storks deliver the babies? Obviously (or so we think) not. Just because two observable quantities correlate does in no way imply that one is the cause of the other. The more likely explanation is that both variables are affected by a common process (i.e., industrialization).\n\nIt is a common mistake to confuse correlation with causation. Another good example is to correlate drinking with heart attacks. This surely will correlate, but the story is more complex. Are there, e.g., patterns like drinkers tend to do less exercise than non-drinkers? So even if you have a good hypothesis why two variables are correlated, the correlation itself proves nothing.\n\nIrrespective of a causal relationship, we can express the correlation between two datasets as the Pearson Product Moment Correlation Coefficient (PPMC, typically called `r`) to describe the strength and direction of the relationship between two variables.   The PPMCC (lower case r) varies between +1 (perfect positive correlation) and -1 (perfect negative or inverse correlation). Correlations are described as weak if they are between +0.3 and -0.3, strong if they are greater than +0.7 or less than -0.7. Note, that correlation analysis makes no assumptions about the functional form between `y` (dependent variable) and `x` (independent variable). In other words, the PPMC says nothing about whether the correlation is linear, logarithmic, exponential etc.\n\nWe can use the `corr()` method of the pandas series object to calculate the PPMCC\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd  # inport pandas as pd\nimport pathlib as pl\n\nfn: str = \"storks_vs_birth_rate.csv\"  # file name\ncwd: pl.Path = pl.Path.cwd()\nfqfn: pl.Path = pl.Path(f\"{cwd}/{fn}\")\n\nif not fqfn.exists():\n    raise FileNotFoundError(f\"Cannot find file {fqfn}\")\n\ndf: pd.DataFrame = pd.read_csv(fn)  # read data\ndf.columns = [\"Babies\", \"Storks\"]  # replace column names \nb: pd.Series = df[\"Babies\"]\ns: pd.Series = df[\"Storks\"]\n\nprint(f\" r = {s.corr(b):.2f}\")"]},{"cell_type":"markdown","metadata":{},"source":["So we can confirm that the number of babies and storks correlate.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Understanding the results of a linear regression analysis\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Linear regression analysis takes correlation analysis one step further and determines how well a linear function (e.g., a straight line) can describe the relation between x and y.  The equation of a straight line `y = mx +b` is fitted to the scatter of data by changing `a` and `m` in such a way that the difference between the measured data and the model prediction is minimized.\n\nThe Coefficient of Determination or r<sup>2</sup> expresses how well a sloping straight line can explain the correlation between the dependent (y) and a single independent (x) variable. In the above figure, r<sup>2</sup> = 0.38, which means that 38% of the new-born babies could be explained by a linear correlation with the number of storks.\n\nIn many cases, more than one independent variable is needed to explain the scatter in the data. In this case, Multiple Linear Regression is used where `y = x1 + x2 + x3….xn + b`. From this analysis (i.e. simultaneous solving for a system of linear equations – remember your Linear Algebra course!) the Multiple Coefficient of Determination (R<sup>2</sup>) is used to express the amount of explained variation in `y` by a combination of independent variables. By default, many programs use the R<sup>2</sup> number even when there is only one independent variable. This can be misleading as capital R<sup>2</sup> should be reserved for analyses that involve multiple independent variables.\n\nFrom a user perspective, we are interested to understand how good the\nmodel is, and how to interpret the key indicators of a given\nregression model:\n\n-   **r<sup>2</sup>:** or the coefficient of determination.  This value is in the range from zero to one and expresses how much of the observed variance  in the data is explained by the regression model. So a value of r<sup>2</sup>=0.7 indicates that 70% of the variance is explained by the model, and that 30% of the variance is explained by other processes which are not captured by the linear model (e.g., measurements errors, or some non-linear effect affecting `x` and `y`). In Fig. [BROKEN LINK: fig:storks] 38% of the variance in the birthrate can be explained by the increase in stork pairs.\n-   **p:** When you do a linear regression, you state the hypothesis that `y` depends on `x` and that they are linked by a linear equation. If you test a hypothesis, you however also have to test the so-called **null-hypothesis**, which in this case would  state that `y` is  unrelated to `x`. The p-value expresses the likelihood that the null-hypothesis is true. So a p-value of 0.1 indicates a 10% chance that your data does not correlate. A p-value of 0.01, indicates a 1% chance that your data is not correlated. Typically, we can reject the null-hypothesis if `p < 0.05`, in other words, we are 95% sure the null hypothesis is wrong. In Fig. [BROKEN LINK: fig:storks], we are 99.2% sure the null hypothesis is wrong. Note that there is not always a simple relationship between r<sup>2</sup> and p.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### The statsmodel library\n\n"]},{"cell_type":"markdown","metadata":{},"source":[" Python's success rests to a considerable degree on the myriad of third party libraries which, unlike MatLab, are typically free to use. In the following, we will use the \"statsmodel\" library, but there are plenty of other statistical libraries we could use as well.\n\nThe statsmodel library provides a few different interfaces. Here we will use the formula interface, which is similar to the R-formula syntax. However, not all statsmodel functions are available through this interface (yet?). First, we import the needed libraries:\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd  # import pandas as pd\nimport pathlib as pl\n\nfn: str = \"storks_vs_birth_rate.csv\"  # file name\ncwd: pl.Path = pl.Path.cwd()\nfqfn: pl.Path = pl.Path(f\"{cwd}/{fn}\")\nif not fqfn.exists():  # check if the file is actually there\n    raise FileNotFoundError(f\"Cannot find file {fqfn}\")\n\ndf: pd.DataFrame = pd.read_csv(fn)  # read data\ndf.columns = [\"Babies\", \"Storks\"]  # replace colum names\ndisplay(df.head())  # test that all went well"]},{"cell_type":"markdown","metadata":{},"source":["For the regression model, we want to analyze whether the number of storks predict the number of babies. In other words, does the birth rate depend on the number of storks? For this, we need to define a statistical model, and test whether the model predictions will fit the data:\n\n-   The gory details of this procedure are beyond the scope of this course - if you have not yet taken a stats class, I do recommend doing so!\n-   There are many ways of doing this. Here we use an approach which is common in `R` (for more details, see [https://www.statsmodels.org/dev/example_formulas.html](https://www.statsmodels.org/dev/example_formulas.html))\n\nAs of March 2024, there is no type hinting support for the statsmodel library.  However, to distinguish between the various statsmodel object types, I use the following hints:\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# smf.ols   ordinary least square model object\n# smf.ols.fit  model results object"]},{"cell_type":"markdown","metadata":{},"source":["See below how this is used in code.\n\nAfter importing the data, we now create a statistical model on line 16 in the code below.  Pay attention to how the model is specified with the formula `\"Babies ~ Storks`, which states that the number of Babies should depend on the number of storks. These names must correspond to the variable names in the data frame `df`! So it is a good ideas to use the `columns()` method to set the column names to single word like \"Babies\" instead of \"Birthrate per year\".\n\nOnce the model is defined, we request to fit the model against the data (line 17) The results of the `fit()` method will be stored in the `results` variable.  Line 18, then invokes the `summary()` method of the results object.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import statsmodels.formula.api as smf\nimport pandas as pd  # import pandas as pd\nimport pathlib as pl\n\nfn: str = \"storks_vs_birth_rate.csv\"  # file name\ncwd: pl.Path = pl.Path.cwd()\nfqfn: pl.Path = pl.Path(f\"{cwd}/{fn}\")\nif not fqfn.exists():  # check if the file is actually there\n    raise FileNotFoundError(f\"Cannot find file {fqfn}\")\n\ndf: pd.DataFrame = pd.read_csv(fn)  # read data\ndf.columns = [\"Babies\", \"Storks\"]  # replace colum names\n\nmodel: smf.ols = smf.ols(formula=\"Babies ~ Storks\", data=df)\nresults: model.fit = model.fit()  # fit the model to the data\ndisplay(results.summary())  # print the results of the analysis"]},{"cell_type":"markdown","metadata":{},"source":["Plenty of information here, probably more than you asked for. Let's tease out the important ones:\n\n-   The first line states that `Babies` is the dependent variable. This is useful and will help you to catch errors in your model definition.\n-   The second line confirms that this is an ordinary least squares model\n-   Then, there are also a couple of warnings, indicating that your data quality may be less than excellent. But we knew this already from testing whether the data is normal distributed or not.\n\nIf you compare the output with Figure [fig:storks](fig:storks), you can see that r<sup>2</sup> value is called \"R-squared\", the p-value is called \"Prob (F-statistic)\", the y-intercept is the first value in the \"Intercept\" row, the slope is the first value in the \"Storks\" row. You can also extract these parameters from the model results object like this:\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["\"\"\" Retrieve parameters from the model results. Note\nthat the dictionary key 'x' must be equal to the\nname of the independent variable used in the model\ndefinition (i.e., y~x)\n\"\"\"\n\nslope: float = results.params[\"x\"]  # the slope\ny_0: float = results.params[\"Intercept\"]  # the y-intercept\nr_square: float = results.rsquared  # rsquare\np_value: float = results.pvalues[\"x\"]  # the p-value"]},{"cell_type":"markdown","metadata":{},"source":["### Adding the regression line and confidence intervals\n\n"]},{"cell_type":"markdown","metadata":{},"source":["The r<sup>2</sup> and p-value give us some indication of how well our regression model performs. However, we can add further information to our graph:\n\n-   The line which represents the regression model\n-   The confidence intervals that indicate the confidence we have in our\n    regression model.\n-   The confidence intervals that indicate the confidence we have in\n    the predictions we make based on our regression model\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Accessing the confidence interval data\n\n"]},{"cell_type":"markdown","metadata":{},"source":["It is not easy to find out how to access these parameters in the statslib library. So best to keep this code snippet in your template collection. Bottom line is, we will use the `summary_table()` function provided by the `statsmodels.stats.outliers_influence` module. We can then feed the `results` object of the regression analysis to this function, and it will return all sorts of data (most of which we can ignore). Note that the `alpha` keyword specifies the significance level for the confidence intervals we aim to retrieve. It is customary to provide this number as 1-significance (e.g., &alpha;=0.05 implies 1-&alpha; = 95%).\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import numpy as np\nimport numpy.typing as npt\nfrom statsmodels.stats.outliers_influence import summary_table\n\n# variable types for the return values from summary_table\nNDArrayFloat = npt.NDArray[np.float64]\nst: summary_table  # table with results that can be printed\ndata: list  # calculated measures and statistics for the table\nss2: list[str]  # column_names for table (Note: rows of table are observations)\n\nsig: float = 0.05  # = 1 - sig > 0.95 = 95% significance\nst, data, ss2 = summary_table(results, alpha=0.05)\n\n# extract the data for predicted values and confidence intervals\nfitted_values: NDArrayFloat  = data[:, 2]  # the regression line\n\n# confidence intervals for the model\nmodel_ci_low: NDArrayFloat   # lower confidence limits\nmodel_ci_upp: NDArrayFloat   # upper confidence limits\nmodel_ci_low, model_ci_upp = data[:, 4:6].T  # don't ask....\n\n# confidence intervals for the model predictions\npredict_mean_ci_low: NDArrayFloat \npredict_mean_ci_upp: NDArrayFloat \npredict_mean_ci_low, predict_mean_ci_upp = data[:, 6:8].T"]},{"cell_type":"markdown","metadata":{},"source":["#### Plotting the confidence interval data\n\n"]},{"cell_type":"markdown","metadata":{},"source":["The upper and lower confidence boundaries describe the upper and lower boundaries of an area. We can either plot these boundaries as a line plot or as a shaded area.  Matplotlib provides the `fill_between` method to shade the area between two lines:\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["ax.fill_between(storks, model_ci_low, model_ci_up, alpha=0.1, color=\"C1\")"]},{"cell_type":"markdown","metadata":{},"source":["Note the use of the `alpha` keyword. This has nothing to do with the alpha which is used in statistics. Rather, it describes the transparency of the object you are drawing. If you set it to one (the default), the object will be fully opaque. If you set it to zero, it will be fully transparent (so you won't see it).  See the code below for an actual example.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Creating the Stork Figure\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Now let's put it all together. Note that when we draw the figure, it matters whether we draw the confidence intervals first or last. Change the order in the code below, to see the difference.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import numpy as np\nimport numpy.typing as npt\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport pathlib as pl\nimport statsmodels.formula.api as smf\nfrom statsmodels.stats.outliers_influence import summary_table\n\nfn: str = \"storks_vs_birth_rate.csv\"  # file name\ncwd: pl.Path = pl.Path.cwd()\nfqfn: pl.Path = pl.Path(f\"{cwd}/{fn}\")\nif not fqfn.exists():  # check if the file is actually there\n    raise FileNotFoundError(f\"Cannot find file {fqfn}\")\n\ndf: pd.DataFrame = pd.read_csv(fn)  # read data\ndf.columns = [\"Babies\", \"Storks\"]  # replace colum names\nstorks: pd.Series = df[\"Storks\"]\nbabies: pd.Series = df[\"Babies\"]\n\n# ------ create linear regression model ------\nmodel: smf.ols = smf.ols(formula=\"Babies ~ Storks\", data=df)\nresults: model.fit = model.fit()  # fit the model to the data\n\n# ------ extract model parameters\nslope: float = results.params[\"Storks\"]  # the slope = name of y\ny_0: float = results.params[\"Intercept\"]  # the y-intercept\nr_square: float = results.rsquared  # r_square\np_value: float = results.pvalues[\"Storks\"]  # the p_value for y\nds: str = (\n    f\"y = {y_0:1.4f}+x*{slope:1.4f}\\n\"\n    f\"$r^2$ = {r_square:1.2f}\\n\"\n    f\"p = {p_value:1.4f}\"\n)\n\n# ------ extract confidence intervals ------\nNDArrayFloat = npt.NDArray[np.float64]\nst: summary_table  # table with results that can be printed\ndata: NDArrayFloat  # calculated measures and statistics for the table\nss2: list[str]  # column_names for table (Note: rows of table are observations)\nmodel_ci_low: NDArrayFloat  # lower confidence value\nmodel_ci_up: NDArrayFloat  # upper confidence number\npredict_mean_ci_low: NDArrayFloat  # lower prediction\npredict_mean_ci_up: NDArrayFloat  # upper prediction\n\n# get data\nsig: float = 0.05  # = 1 - sig > 0.95 = 95% significance\nst, data, ss2 = summary_table(results, alpha=sig)\nfitted_values: NDArrayFloat = data[:, 2]\nmodel_ci_low, model_ci_up = data[:, 4:6].T  #\npredict_mean_ci_low, predict_mean_ci_up = data[:, 6:8].T\n\n# ------ create plot ------\nfig: plt.Figure  # this variable  will hold the canvas object\nax: plt.Axes  # this variable will hold the axis object\nfig, ax = plt.subplots()  # create canvas and axis objects\n\n# plot confidence intervals first\nax.fill_between(storks, predict_mean_ci_low, predict_mean_ci_up, alpha=0.1, color=\"C1\")\nax.fill_between(storks, model_ci_low, model_ci_up, alpha=0.2, color=\"C1\")\n# add data points\nax.scatter(storks, babies, color=\"C0\")\n# regression line\nax.plot(storks, fitted_values, color=\"C1\")\n# plot options and annotations\nplt.style.use(\"ggplot\")\nfig.set_size_inches(6, 4)\nfig.set_dpi(120)\nax.text(1000, 1750, ds, verticalalignment=\"top\")\nax.set_xlabel(\"Stork Pairs\")\nax.set_ylabel(\"Newborn Babies [$10^3$]\")\nfig.set_tight_layout(\"tight\")\nfig.savefig(\"stork_new.png\")\nplt.show()"]},{"cell_type":"markdown","metadata":{},"source":["The code above is quite lengthy, especially given the fact that you can do a regression analysis with a few clicks in Excel. On the other hand, if you re-arrange the code a little bit, and use generic variables, you can create a code template where you only specify a few key parameters at the beginning of the code, and then you can generate a much more meaningful regression analysis with a few keystrokes:\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["\"\"\" Description:\n    Author:\n    Date:\n\"\"\"\n# ----------- third party library imports ------------------\nimport pandas as pd  # inport pandas as pd\nimport matplotlib.pyplot as plt\nimport pathlib as pl\nimport statsmodels.formula.api as smf\nfrom statsmodels.stats.outliers_influence import summary_table\n\n# ----------- user serviceable pararameters\ndata_file: str = \"\"  # csv file name\nfigure_name: str = \"\"  # figure name\n\nindependent_variable: str = \"\"  # must match col name\ndependent_variable: str = \"\"  # must match col name\n\nx_axis_label: str = \"\"\ny_axis_label: str = \"\"\nsize_x: number = 6  # size in inches\nsize_y: number = 4  # size in inches\n\nconfidence_level: float = 0.05  # 1 - alpha in %\n\n# ----------- main program ---------------------------------\n# --- variable declarations\n\n# --- code starts here"]},{"cell_type":"markdown","metadata":{},"source":["### Testing the data\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Histograms\n\n"]},{"cell_type":"markdown","metadata":{},"source":["The Storks data set is fun, but it violates a fundamental requirement for a linear regression analysis: \n\n-   Regression analysis is only valid if your data shows a [Gaussian Normal Distribution](https://en.wikipedia.org/wiki/Normal_distribution) (or bell curve). To get a quick idea of how your data is distributed, we can use a [histogram plot](https://en.wikipedia.org/wiki/Histogram) test whether the x and y values are normal distributed or not.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n\nfig: plt.Figure\nax1: plt.Axes\nax2: plt.Axes\n\nfig, [ax1, ax2] = plt.subplots(nrows=2, ncols=1)  #\nax1.hist(\n    df.iloc[:, 0],\n)\nax2.hist(df.iloc[:, 1])\nax1.set_title(\"Babies\")\nax2.set_title(\"Storks\")\nplt.show()"]},{"cell_type":"markdown","metadata":{},"source":["As you can see from the histogram, our data shows anything but a normal distribution! We will use it anyway since it is a fun dataset. However, the above test is crucial if you ever want to do a real regression analysis!\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Qqplots\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Another way to test for normality is to use a [qqplot](https://en.wikipedia.org/wiki/Q%E2%80%93Q_plot) to test whether your data  is normal distributed. Alas, the statsmodel qqplot function does not follow the usual matplolib syntax, and there is no easy way to control the colors. \n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import statsmodels.api as sm\n\nfig, ax = plt.subplots()\nsm.qqplot(df.Y, ax=ax, line=\"s\")\nplt.show()"]},{"cell_type":"markdown","metadata":{},"source":["#### The Shapiro-Wilk Test\n\n"]},{"cell_type":"markdown","metadata":{},"source":["The [Shapiro-Wilk test](https://en.wikipedia.org/wiki/Shapiro%E2%80%93Wilk_test)   provides a programmatical  way to test for a normal distribution. The snippet below shows how to use and interpret it.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from scipy.stats import shapiro\n\n# Do a Shapiro Wilk test\nstat, p = shapiro(np.log(df.X))\nprint(f\"Shapiro Wilk Test Statistics = {stat:.3f}, p = {p:.3f}\")\n\n# interpretation\nalpha = 0.05  # = 95% confidence level\nif p > alpha:\n    print(\n        f\"Sample looks Gaussian, the Shapiro test failed to reject H0 at the {(1-alpha)*100:.0f}% confidence level\"\n    )\nelse:\n    print(\n        f\"Sample does not looks Gaussian, the Shapiro test confirmed H0 at the {(1-alpha)*100:.0f}% confidence level\"\n    )"]},{"cell_type":"markdown","metadata":{},"source":["### References\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   Robert Matthews, Storks Devilver Babies (p = 0.008), Teaching\n    Statistics 22:2, p 36-38, 2000,\n    [https://doi.org/10.1111/1467-9639.00013](https://doi.org/10.1111/1467-9639.00013)\n\n"]}],"metadata":{"org":null,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}